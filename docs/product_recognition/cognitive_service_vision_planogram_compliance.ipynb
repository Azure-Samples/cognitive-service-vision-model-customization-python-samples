{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Cognitive Service Vision Planogram Compliance using Python\n",
    "\n",
    "This is a tutorial about using Cognitive Service Vision Planogram Compliance. Cognitive Service Vision Planogram Compliance are tools to check planogram compliance using planogram and product recognition result\n",
    "\n",
    "Currently, planogram compliance feature are available in **EastUS**, **West US2**, and **West Europe** regions.\n",
    "\n",
    "Please create a computer vision resource on Azure portal, in **EastUS**, **West US2**, or **West Europe** region, if you don't already have one. You can use [Multi-service resource](https://learn.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account?tabs=multiservice%2Canomaly-detector%2Clanguage-service%2Ccomputer-vision%2Cwindows) as well. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the python samples package\n",
    "\n",
    "Install the sample code including utility code helping you use Python to run planogram compliance in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cognitive-service-vision-model-customization-python-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource and key\n",
    "import json\n",
    "import logging\n",
    "import uuid\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from cognitive_service_vision_model_customization_python_samples import ResourceType\n",
    "from cognitive_service_vision_model_customization_python_samples.clients import PlanogramComplianceClient, ProductRecognitionClient\n",
    "from cognitive_service_vision_model_customization_python_samples.models import PlanogramMatchingRequest, ProductRecognition\n",
    "from cognitive_service_vision_model_customization_python_samples.tools import visualize_planogram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "Resource name and resource key are needed for accessing the service, which you can find here:\n",
    "\n",
    "![check media/credentials.png if pic does not show up](./resources/credentials.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource and key\n",
    "# resource_type = ResourceType.SINGLE_SERVICE_RESOURCE # or ResourceType.MULTI_SERVICE_RESOURCE\n",
    "resource_type = ResourceType.MULTI_SERVICE_RESOURCE\n",
    "\n",
    "resource_name = None\n",
    "multi_service_endpoint = None\n",
    "\n",
    "if resource_type == ResourceType.SINGLE_SERVICE_RESOURCE:\n",
    "    resource_name = 'https://kualutestapim.azure-api.net/'\n",
    "    assert resource_name\n",
    "else:\n",
    "    multi_service_endpoint = 'https://kualutestapim.azure-api.net/'\n",
    "    assert multi_service_endpoint\n",
    "\n",
    "resource_key = '26fd020ee20f4d2080be9ea42c1f69d6'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and load the planogram\n",
    "\n",
    "A planogram, also known as a plano, POG, plan-o-gram, schematic, or visual description, is a detailed visual map that establishes the position of the merchandise within a retail store. It is often used in the retail industry as a tool for space planning and product placement. This diagram shows precisely where each item in a store should be placed in order to maximize customer purchases.\n",
    "\n",
    "Below is a visualization of a sample planogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAALQCAIAAADpYRVgAAAKiElEQVR4nO3dwYriWhRA0dwi///L6YHS+ChaU7yYa+2sNclAwZPG2h7TYJYFAAAAAAAAAAAAAAAAAAAAAAAA+Hhj9gCcaJs9AHP5c7+Sr9kDcBZlx3vgSsQdIGj4ML+cKd/N/77N5r66AbgMmztAkLgDBK3346X+G33uJYJZfDHn5ppv++udtc0dIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgtb7cZs6xSzXPGsu7ppv++ud9bjeKQP0uSwDECTuAEH3a+5j7hQAHGezuQMkiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEuVkHQJDNHSBI3AEAAAAAAAAAAAAAAAAA+Jmx+HEZgJKxLH5+AKBmWxZxB0ha78cxdYqTPV6JcuJX4MQXJ34NDyducwcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAoPGfO8kCEDBs7gBF4g4QtN6PY+oUJ3u8EuXEr8CJL078Gh5O3OYOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQWPZZo8AwLHGMrQdoMdlGYAgcQcIWm+HMXcKAI6z2dwBksQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgtysAyDI5g4QJO4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5Y/YA/7DNHgDgcCcW9+u8l9pP2YGkE+P2kXEH4P9ZZw/w1NyLRo+fsSa5Mcl3JvnOJN+dfkHC5g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQWObPQEAh7O5AwSJO0DQejuMuVMAcJzN5g6QJO4AQeIOECTuAEHiDhAk7gBB4g4QJO4AQeIOECTuAEHiDhAk7gBB4g4Q5GYdAEE2d4AgcQcAAAAAAAAAAAAAAAAAAAAAAIBfYLx43C8CA3yOV83+6+mvQio7wEfZnWU/+QsQtO561u4vAm/3+KllqudMtZ+p9jPVfsdO9cNLKTZ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwga2+wJADiczR0gSNwBgtbbYcydAoDjbDZ3gCRxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCA36wAIsrkDBIk7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAznjx+HbKFFzN8Nbiwl519/0v4s8P4B3e3/evt78CAKdbdz3rlC8Ruzx+mTDVc58/1fJJgy2f+i+2GOznfsVgb2ZzBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4Cgsc2eAIDD2dwBgsQdIGi9HcbcKQA4zmZzB0gSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwhysw6AIJs7QJC4AwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA5IwXj2+nTAHATz3t99ezB5Ud4GM9TfTTuAPwO627nvXq4s15Hj+pTPWcqfYz1X6m2u99U+24rGJzBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4Cgsc2eAIDD2dwBgsQdIGi9HcbcKQA4zmZzB0gSd4AgcQcIEneAIHEHCBJ3gCBxBwgSd4AgcQcIEneAIHEHCBJ3gCBxBwhysw6AIJs7QJC4AwAAAAAAAAAAAADwSf4A0pZot5jBujUAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=500x720>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "planogram = json.load(open('./resources/sample_planogram.json', 'r'))\n",
    "viz_planogram = visualize_planogram(planogram, 500)\n",
    "viz_planogram = cv2.cvtColor(viz_planogram, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(viz_planogram))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call product recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Product recognition running fd80f6d1-4f2a-4844-8b43-27a586e25d9a for 2.2742936611175537 seconds. Status ProductRecognitionStatus.RUNNING.\n",
      "INFO:root:Product recognition running fd80f6d1-4f2a-4844-8b43-27a586e25d9a for 4.540368556976318 seconds. Status ProductRecognitionStatus.RUNNING.\n",
      "INFO:root:Product recognition running fd80f6d1-4f2a-4844-8b43-27a586e25d9a for 6.803614377975464 seconds. Status ProductRecognitionStatus.RUNNING.\n",
      "INFO:root:Product recognition running fd80f6d1-4f2a-4844-8b43-27a586e25d9a for 9.070351839065552 seconds. Status ProductRecognitionStatus.RUNNING.\n",
      "INFO:cognitive_service_vision_model_customization_python_samples.clients.product_recognition_client:Product recognition finished with state ProductRecognitionStatus.SUCCEEDED.\n",
      "INFO:cognitive_service_vision_model_customization_python_samples.clients.product_recognition_client:Wall-clock time 0.15117253065109254 minutes.\n",
      "INFO:cognitive_service_vision_model_customization_python_samples.clients.product_recognition_client:Product recognition result: {'imageMetadata': {'width': 2586, 'height': 3161}, 'products': [{'id': '1', 'boundingBox': {'x': 408, 'y': 66, 'w': 431, 'h': 366}, 'tags': [{'name': 'product', 'confidence': 0.9768970012664795}]}, {'id': '2', 'boundingBox': {'x': 1734, 'y': 69, 'w': 437, 'h': 357}, 'tags': [{'name': 'product', 'confidence': 0.9728712439537048}]}, {'id': '3', 'boundingBox': {'x': 1408, 'y': 2153, 'w': 264, 'h': 386}, 'tags': [{'name': 'product', 'confidence': 0.9722458124160767}]}, {'id': '4', 'boundingBox': {'x': 319, 'y': 1640, 'w': 267, 'h': 375}, 'tags': [{'name': 'product', 'confidence': 0.9708327054977417}]}, {'id': '5', 'boundingBox': {'x': 587, 'y': 1642, 'w': 261, 'h': 370}, 'tags': [{'name': 'product', 'confidence': 0.970481276512146}]}, {'id': '6', 'boundingBox': {'x': 1145, 'y': 2152, 'w': 265, 'h': 386}, 'tags': [{'name': 'product', 'confidence': 0.9703117609024048}]}, {'id': '7', 'boundingBox': {'x': 852, 'y': 1639, 'w': 255, 'h': 370}, 'tags': [{'name': 'product', 'confidence': 0.9698547124862671}]}, {'id': '8', 'boundingBox': {'x': 359, 'y': 2160, 'w': 260, 'h': 381}, 'tags': [{'name': 'product', 'confidence': 0.9693546891212463}]}, {'id': '9', 'boundingBox': {'x': 621, 'y': 2160, 'w': 260, 'h': 380}, 'tags': [{'name': 'product', 'confidence': 0.9686022400856018}]}, {'id': '10', 'boundingBox': {'x': 1625, 'y': 1636, 'w': 262, 'h': 370}, 'tags': [{'name': 'product', 'confidence': 0.9685074687004089}]}, {'id': '11', 'boundingBox': {'x': 878, 'y': 646, 'w': 434, 'h': 369}, 'tags': [{'name': 'product', 'confidence': 0.9684134721755981}]}, {'id': '12', 'boundingBox': {'x': 1369, 'y': 1636, 'w': 255, 'h': 370}, 'tags': [{'name': 'product', 'confidence': 0.9675979614257812}]}, {'id': '13', 'boundingBox': {'x': 1890, 'y': 1628, 'w': 267, 'h': 378}, 'tags': [{'name': 'product', 'confidence': 0.9675582051277161}]}, {'id': '14', 'boundingBox': {'x': 1752, 'y': 637, 'w': 426, 'h': 375}, 'tags': [{'name': 'product', 'confidence': 0.9672552943229675}]}, {'id': '15', 'boundingBox': {'x': 886, 'y': 2157, 'w': 257, 'h': 379}, 'tags': [{'name': 'product', 'confidence': 0.9669260382652283}]}, {'id': '16', 'boundingBox': {'x': 15, 'y': 643, 'w': 428, 'h': 371}, 'tags': [{'name': 'product', 'confidence': 0.9663529396057129}]}, {'id': '17', 'boundingBox': {'x': 290, 'y': 2713, 'w': 262, 'h': 370}, 'tags': [{'name': 'product', 'confidence': 0.9660894274711609}]}, {'id': '18', 'boundingBox': {'x': 444, 'y': 642, 'w': 437, 'h': 373}, 'tags': [{'name': 'product', 'confidence': 0.9659836888313293}]}, {'id': '19', 'boundingBox': {'x': 1111, 'y': 1680, 'w': 254, 'h': 328}, 'tags': [{'name': 'product', 'confidence': 0.9655609130859375}]}, {'id': '20', 'boundingBox': {'x': 1312, 'y': 644, 'w': 431, 'h': 369}, 'tags': [{'name': 'product', 'confidence': 0.9653034806251526}]}, {'id': '21', 'boundingBox': {'x': 92, 'y': 2162, 'w': 264, 'h': 378}, 'tags': [{'name': 'product', 'confidence': 0.9652042388916016}]}, {'id': '22', 'boundingBox': {'x': 2167, 'y': 59, 'w': 417, 'h': 363}, 'tags': [{'name': 'product', 'confidence': 0.9651398062705994}]}, {'id': '23', 'boundingBox': {'x': 1674, 'y': 2154, 'w': 267, 'h': 384}, 'tags': [{'name': 'product', 'confidence': 0.9643312096595764}]}, {'id': '24', 'boundingBox': {'x': 1292, 'y': 54, 'w': 219, 'h': 375}, 'tags': [{'name': 'product', 'confidence': 0.9628825187683105}]}, {'id': '25', 'boundingBox': {'x': 0, 'y': 60, 'w': 410, 'h': 371}, 'tags': [{'name': 'product', 'confidence': 0.9624803066253662}]}, {'id': '26', 'boundingBox': {'x': 1937, 'y': 2154, 'w': 269, 'h': 385}, 'tags': [{'name': 'product', 'confidence': 0.962049663066864}]}, {'id': '27', 'boundingBox': {'x': 2206, 'y': 2158, 'w': 267, 'h': 381}, 'tags': [{'name': 'product', 'confidence': 0.961605966091156}]}, {'id': '28', 'boundingBox': {'x': 2171, 'y': 644, 'w': 414, 'h': 364}, 'tags': [{'name': 'product', 'confidence': 0.9607388377189636}]}, {'id': '29', 'boundingBox': {'x': 842, 'y': 59, 'w': 222, 'h': 371}, 'tags': [{'name': 'product', 'confidence': 0.9600987434387207}]}, {'id': '30', 'boundingBox': {'x': 1879, 'y': 2710, 'w': 263, 'h': 373}, 'tags': [{'name': 'product', 'confidence': 0.9593765139579773}]}, {'id': '31', 'boundingBox': {'x': 1614, 'y': 2705, 'w': 263, 'h': 375}, 'tags': [{'name': 'product', 'confidence': 0.9577333927154541}]}, {'id': '32', 'boundingBox': {'x': 26, 'y': 2718, 'w': 261, 'h': 358}, 'tags': [{'name': 'product', 'confidence': 0.9574331045150757}]}, {'id': '33', 'boundingBox': {'x': 1065, 'y': 55, 'w': 222, 'h': 374}, 'tags': [{'name': 'product', 'confidence': 0.9558418393135071}]}, {'id': '34', 'boundingBox': {'x': 1092, 'y': 2699, 'w': 259, 'h': 381}, 'tags': [{'name': 'product', 'confidence': 0.9536006450653076}]}, {'id': '35', 'boundingBox': {'x': 830, 'y': 2710, 'w': 260, 'h': 369}, 'tags': [{'name': 'product', 'confidence': 0.9517771601676941}]}, {'id': '36', 'boundingBox': {'x': 1351, 'y': 2703, 'w': 262, 'h': 380}, 'tags': [{'name': 'product', 'confidence': 0.9510535597801208}]}, {'id': '37', 'boundingBox': {'x': 438, 'y': 1163, 'w': 246, 'h': 362}, 'tags': [{'name': 'product', 'confidence': 0.9505004286766052}]}, {'id': '38', 'boundingBox': {'x': 2142, 'y': 2719, 'w': 261, 'h': 359}, 'tags': [{'name': 'product', 'confidence': 0.948496401309967}]}, {'id': '39', 'boundingBox': {'x': 681, 'y': 1163, 'w': 248, 'h': 358}, 'tags': [{'name': 'product', 'confidence': 0.9424803853034973}]}, {'id': '40', 'boundingBox': {'x': 931, 'y': 1152, 'w': 238, 'h': 366}, 'tags': [{'name': 'product', 'confidence': 0.9419150352478027}]}, {'id': '41', 'boundingBox': {'x': 1646, 'y': 1145, 'w': 253, 'h': 372}, 'tags': [{'name': 'product', 'confidence': 0.9419048428535461}]}, {'id': '42', 'boundingBox': {'x': 1890, 'y': 1172, 'w': 259, 'h': 342}, 'tags': [{'name': 'product', 'confidence': 0.9412358999252319}]}, {'id': '43', 'boundingBox': {'x': 22, 'y': 546, 'w': 425, 'h': 95}, 'tags': [{'name': 'product', 'confidence': 0.9409496188163757}]}, {'id': '44', 'boundingBox': {'x': 2161, 'y': 1628, 'w': 265, 'h': 381}, 'tags': [{'name': 'product', 'confidence': 0.9396277666091919}]}, {'id': '45', 'boundingBox': {'x': 1405, 'y': 1162, 'w': 247, 'h': 355}, 'tags': [{'name': 'product', 'confidence': 0.9376854300498962}]}, {'id': '46', 'boundingBox': {'x': 2124, 'y': 1148, 'w': 277, 'h': 368}, 'tags': [{'name': 'product', 'confidence': 0.9362070560455322}]}, {'id': '47', 'boundingBox': {'x': 1169, 'y': 1151, 'w': 239, 'h': 365}, 'tags': [{'name': 'product', 'confidence': 0.934772789478302}]}, {'id': '48', 'boundingBox': {'x': 1742, 'y': 543, 'w': 420, 'h': 93}, 'tags': [{'name': 'product', 'confidence': 0.9328019618988037}]}, {'id': '49', 'boundingBox': {'x': 2166, 'y': 534, 'w': 416, 'h': 102}, 'tags': [{'name': 'product', 'confidence': 0.9311664700508118}]}, {'id': '50', 'boundingBox': {'x': 111, 'y': 1614, 'w': 238, 'h': 365}, 'tags': [{'name': 'product', 'confidence': 0.927588939666748}]}, {'id': '51', 'boundingBox': {'x': 1310, 'y': 539, 'w': 426, 'h': 99}, 'tags': [{'name': 'product', 'confidence': 0.9248338341712952}]}, {'id': '52', 'boundingBox': {'x': 454, 'y': 549, 'w': 426, 'h': 91}, 'tags': [{'name': 'product', 'confidence': 0.922010600566864}]}, {'id': '54', 'boundingBox': {'x': 2398, 'y': 2690, 'w': 141, 'h': 381}, 'tags': [{'name': 'product', 'confidence': 0.8802869915962219}]}, {'id': '55', 'boundingBox': {'x': 885, 'y': 553, 'w': 422, 'h': 90}, 'tags': [{'name': 'product', 'confidence': 0.8378040194511414}]}, {'id': '57', 'boundingBox': {'x': 2430, 'y': 1632, 'w': 119, 'h': 373}, 'tags': [{'name': 'product', 'confidence': 0.7863534092903137}]}, {'id': '58', 'boundingBox': {'x': 663, 'y': 2606, 'w': 199, 'h': 189}, 'tags': [{'name': 'product', 'confidence': 0.5052991509437561}]}, {'id': '59', 'boundingBox': {'x': 2101, 'y': 2089, 'w': 258, 'h': 42}, 'tags': [{'name': 'product', 'confidence': 0.14365331828594208}]}], 'gaps': [{'id': '53', 'boundingBox': {'x': 59, 'y': 1081, 'w': 374, 'h': 448}, 'tags': [{'name': 'gap', 'confidence': 0.8853721618652344}]}, {'id': '56', 'boundingBox': {'x': 1518, 'y': 0, 'w': 203, 'h': 425}, 'tags': [{'name': 'gap', 'confidence': 0.8259734511375427}]}]}\n"
     ]
    }
   ],
   "source": [
    "client = ProductRecognitionClient(resource_type, resource_name, multi_service_endpoint, resource_key)\n",
    "run_name = str(uuid.uuid4())\n",
    "model_name = 'ms-pretrained-product-detection'\n",
    "run = ProductRecognition(run_name, model_name)\n",
    "\n",
    "with open('./resources/sample_image.jpg', 'rb') as f:\n",
    "    img = f.read()\n",
    "\n",
    "try:\n",
    "    client.create_run(run, img, 'image/png')\n",
    "    result = client.wait_for_completion(run_name, model_name)\n",
    "finally:\n",
    "    client.delete_run(run_name, model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call planogram matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PlanogramComplianceClient(resource_type, resource_name, multi_service_endpoint, resource_key)\n",
    "matching_request = PlanogramMatchingRequest(result.result, planogram)\n",
    "result = client.match_planogram(matching_request)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
